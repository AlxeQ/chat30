import os
import pandas as pd
import docx2txt
import tempfile
import pdfplumber
import requests
import streamlit as st

# ä»ç¯å¢ƒå˜é‡è¯»å–DeepSeek API Key
DEEPSEEK_API_KEY = os.environ.get("DEEPSEEK_API_KEY")

def call_deepseek_api(prompt):
    url = "https://api.deepseek.com/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}"
    }
    data = {
        "model": "deepseek-chat",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.7
    }
    response = requests.post(url, headers=headers, json=data)
    if response.status_code == 200:
        return response.json()['choices'][0]['message']['content']
    else:
        return f"è°ƒç”¨ DeepSeek API å¤±è´¥ï¼ŒçŠ¶æ€ç  {response.status_code}: {response.text}"

def extract_text_from_pdf(uploaded_file):
    text = ""
    with pdfplumber.open(uploaded_file) as pdf:
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text + "\n"
    return text

def extract_text_from_docx(uploaded_file):
    with tempfile.NamedTemporaryFile(delete=False, suffix=".docx") as tmp:
        tmp.write(uploaded_file.read())
        tmp.flush()
        text = docx2txt.process(tmp.name)
    return text

def extract_text(file):
    if file.name.endswith(".pdf"):
        return extract_text_from_pdf(file)
    elif file.name.endswith(".docx"):
        return extract_text_from_docx(file)
    elif file.name.endswith(".txt"):
        return file.read().decode("utf-8")
    else:
        return "ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹"

def analyze_interview(transcript, outline):
    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è®¿è°ˆåˆ†æä¸“å®¶ï¼Œè¯·æ ¹æ®ä»¥ä¸‹æ­¥éª¤å¯¹è®¿è°ˆå†…å®¹è¿›è¡Œç»“æ„åŒ–åˆ†æï¼š

ä¸€ã€åˆ†æè¦æ±‚
1. è¯†åˆ«è®¿è°ˆä¸­ä¸å¤§çº²å¯¹åº”çš„å†…å®¹ï¼Œåˆ†æè¦†ç›–ç¨‹åº¦
2. ç‰¹åˆ«æ³¨æ„å‘ç°å¤§çº²æœªæ¶µç›–ä½†å…·æœ‰ä»·å€¼çš„æ¡ˆä¾‹ã€æ•…äº‹ã€æ•°æ®ç­‰é¢å¤–ä¿¡æ¯
3. å¯¹éœ€è¦æ·±å…¥çš„å†…å®¹ç»™å‡ºå…·ä½“å¯æ“ä½œçš„è¡¥é—®å»ºè®®

äºŒã€ç»“æ„åŒ–æ•´ç†
è¯·ç”ŸæˆåŒ…å«ä»¥ä¸‹åˆ†æçš„Markdownè¡¨æ ¼ï¼š

| å†…å®¹ç±»å‹ | å¤§çº²é—®é¢˜/å‘ç°ä¸»é¢˜ | è¯¦ç»†æ‘˜è¦ | è¦†ç›–ç¨‹åº¦ | å»ºè®®è¡¥é—®é—®é¢˜ |
|----------|-------------------|----------|----------|--------------|
# è¡¨æ ¼å†…å®¹åº”åŒ…å«ï¼š
A. å¤§çº²åŒ¹é…éƒ¨åˆ†ï¼š
   - å†…å®¹ç±»å‹å¡«å†™"å¤§çº²å¯¹åº”"
   - è¦†ç›–ç¨‹åº¦æ ‡æ³¨ï¼ˆå……åˆ†/éƒ¨åˆ†/æœªè¦†ç›–ï¼‰
   - è¯¦ç»†æ‘˜è¦éœ€åŒ…å«å…·ä½“è®ºæ®å’Œå…³é”®æ•°æ®
   - å»ºè®®è¡¥é—®è¦å…·ä½“å¯æ“ä½œï¼ˆå¦‚æœªè¦†ç›–åˆ™å¿…å¡«ï¼‰

B. é¢å¤–ä»·å€¼ä¿¡æ¯ï¼š
   - å†…å®¹ç±»å‹å¡«å†™"é¢å¤–å‘ç°"
   - è¦†ç›–ç¨‹åº¦æ ‡æ³¨"N/A"
   - è¯¦ç»†æ‘˜è¦éœ€çªå‡ºä¿¡æ¯ä»·å€¼ç‚¹
   - å»ºè®®è¡¥é—®å¯å¡«å†™å»¶ä¼¸æŒ–æ˜æ–¹å‘

ä¸‰ã€åˆ†æç»´åº¦
1. å¯¹æ¯ä¸ªå¤§çº²é—®é¢˜ï¼š
   - æå–3-5ä¸ªå…³é”®ä¿¡æ¯ç‚¹
   - åŒºåˆ†æ ¸å¿ƒè¦ç‚¹å’Œè¡¥å……ä¿¡æ¯
   - æ ‡æ³¨å—è®¿è€…çš„å…¸å‹è¯æœ¯

2. å¯¹é¢å¤–ä¿¡æ¯ï¼š
   - è¯†åˆ«æœ‰ä¸šåŠ¡ä»·å€¼çš„æ¡ˆä¾‹ï¼ˆæˆåŠŸ/å¤±è´¥ç»éªŒï¼‰
   - å‘ç°å€¼å¾—è¿½è¸ªçš„æ•°æ®çº¿ç´¢
   - æ ‡æ³¨å…¸å‹ç”¨æˆ·æ•…äº‹

å››ã€æ ¼å¼è¦æ±‚
1. ä½¿ç”¨ä¸¥è°¨çš„Markdownè¡¨æ ¼æ ¼å¼
2. ä¿æŒå„åˆ—æ–‡å­—ç®€æ´ï¼ˆæ¯å•å…ƒæ ¼ä¸è¶…è¿‡50å­—ï¼‰
3. é‡è¦å†…å®¹ä½¿ç”¨**åŠ ç²—**å¼ºè°ƒ

è¯·åŸºäºä»¥ä¸‹ææ–™è¿›è¡Œåˆ†æï¼š
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
è®¿è°ˆå¤§çº²è¦æ±‚ï¼š
{outline}

è®¿è°ˆè®°å½•å…¨æ–‡ï¼š
{transcript}
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
"""
    return call_deepseek_api(prompt)

def main():
    st.set_page_config(page_title="è®¿è°ˆç»“æ„æ•´ç†å·¥å…·", layout="wide")
    st.title("ğŸ“‹ è®¿è°ˆç»“æ„æ•´ç† MVP å·¥å…·")

    st.markdown("### ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ è®¿è°ˆæ–‡ä»¶ï¼ˆpdfã€docxã€txtï¼‰")
    interview_file = st.file_uploader("ä¸Šä¼ è®¿è°ˆè®°å½•æ–‡ä»¶ï¼š", type=["pdf", "docx", "txt"])

    st.markdown("### ç¬¬äºŒæ­¥ï¼šä¸Šä¼ è®¿è°ˆå¤§çº²ï¼ˆdocxã€txtï¼‰")
    outline_file = st.file_uploader("ä¸Šä¼ è®¿è°ˆå¤§çº²æ–‡ä»¶ï¼š", type=["docx", "txt"])

    if st.button("ğŸš€ å¼€å§‹åˆ†æ") and interview_file and outline_file:
        with st.spinner("â³ æ­£åœ¨æå–ä¸åˆ†æå†…å®¹ï¼Œè¯·ç¨å€™..."):
            transcript = extract_text(interview_file)
            outline = extract_text(outline_file)

            result_markdown = analyze_interview(transcript, outline)

        st.markdown("### âœ… åˆ†æç»“æœ")
        # ä¿®æ”¹è¿™é‡Œï¼šç§»é™¤unsafe_allow_html=Trueå‚æ•°
        st.markdown(result_markdown)

        # å¯¼å‡ºExcelæŒ‰é’®
        try:
            df_list = pd.read_html(result_markdown, flavor="bs4")
            if df_list:
                df = df_list[0]
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½ç»“æœä¸º Excel",
                    data=df.to_excel(index=False, engine='openpyxl'),
                    file_name="interview_analysis.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                st.warning("âš ï¸ æœªèƒ½è¯†åˆ«è¡¨æ ¼æ•°æ®ï¼Œè¯·æ£€æŸ¥è¿”å›çš„Markdownæ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚")
        except Exception as e:
            st.error(f"âŒ è½¬æ¢ç»“æœå¤±è´¥ï¼š{e}")

if __name__ == "__main__":
    main()