import io
import os
import pandas as pd
import docx2txt
import tempfile
import pdfplumber
import requests
import streamlit as st

# ä»ç¯å¢ƒå˜é‡è¯»å–DeepSeek API Key
DEEPSEEK_API_KEY = os.environ.get("DEEPSEEK_API_KEY")

def call_deepseek_api(prompt):
    url = "https://api.deepseek.com/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}"
    }
    data = {
        "model": "deepseek-chat",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.7
    }
    response = requests.post(url, headers=headers, json=data)
    if response.status_code == 200:
        return response.json()['choices'][0]['message']['content']
    else:
        return f"è°ƒç”¨ DeepSeek API å¤±è´¥ï¼ŒçŠ¶æ€ç  {response.status_code}: {response.text}"

def extract_text_from_pdf(uploaded_file):
    text = ""
    with pdfplumber.open(uploaded_file) as pdf:
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text + "\n"
    return text

def extract_text_from_docx(uploaded_file):
    with tempfile.NamedTemporaryFile(delete=False, suffix=".docx") as tmp:
        tmp.write(uploaded_file.read())
        tmp.flush()
        text = docx2txt.process(tmp.name)
    return text

def extract_text(file):
    if file.name.endswith(".pdf"):
        return extract_text_from_pdf(file)
    elif file.name.endswith(".docx"):
        return extract_text_from_docx(file)
    elif file.name.endswith(".txt"):
        return file.read().decode("utf-8")
    else:
        return "ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹"

def analyze_interview(transcript, outline, target):
    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è®¿è°ˆå†…å®¹ç»“æ„åŒ–è®°å½•ä¸“å®¶ï¼Œä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©å›¢é˜Ÿ**å®Œæ•´è¿˜åŸå—è®¿è€…è®²è¿°çš„æ¯ä¸ªè§‚ç‚¹ã€å®Œæ•´æ¡ˆä¾‹ä¸ç»†èŠ‚**ï¼Œå¹¶å°†å…¶ä¸è®¿è°ˆå¤§çº²é€ä¸€æ¯”å¯¹ã€åˆ†ç±»å½’æ¡£ã€‚

**ä¸€ã€å¤§çº²é€æ¡æ¯”å¯¹**
- è¯·éå†ä»¥ä¸‹è®¿è°ˆå¤§çº²ä¸­çš„æ¯ä¸ªé—®é¢˜ï¼Œåˆ¤æ–­è®¿è°ˆä¸­æ˜¯å¦è¿›è¡Œäº†å›ç­”ã€‚
- è‹¥æœ‰å›ç­”ï¼Œè¯·å®Œæ•´æå–å¯¹åº”å†…å®¹ï¼Œä¿ç•™å…¸å‹è¯´æ³•ã€å…³é”®æ•°æ®ã€å…·ä½“ç»†èŠ‚ã€‚
- è‹¥æ— æ˜ç¡®å›ç­”ï¼Œè¯·æå‡ºå¯ç›´æ¥ç”¨äºè¡¥å……è®¿è°ˆçš„å…·ä½“è¡¥é—®å»ºè®®ã€‚

**äºŒã€æ¡ˆä¾‹ä¸çº¿ç´¢æŠ½å–**
- è¯†åˆ«è®¿è°ˆä¸­æ‰€æœ‰åŒ…å«æ—¶é—´ã€äººç‰©ã€äº‹ä»¶ã€ç»“æœçš„å®Œæ•´æ¡ˆä¾‹ä¸ç»éªŒåˆ†äº«ã€‚
- æå–å…¶ä¸­çš„å…³é”®æ•…äº‹ã€æˆè´¥ç»éªŒã€é‡åŒ–æ•°æ®ã€å¯è¿½é—®çš„çº¿ç´¢ã€‚

**ä¸‰ã€è¾“å‡ºæ ¼å¼ï¼ˆMarkdownè¡¨æ ¼ï¼‰**
è¯·ç”Ÿæˆå¦‚ä¸‹æ ¼å¼çš„è¡¨æ ¼ï¼ˆä¸é™äºå¤§çº²é—®é¢˜ï¼‰ï¼š

| ç±»å‹ | é—®é¢˜æˆ–ä¸»é¢˜ | å†…å®¹æ‘˜è¦ | åŸå§‹è¯æœ¯ | è¦†ç›–æƒ…å†µ | è¡¥é—®å»ºè®® |
|------|------------|----------|-----------|-----------|-----------|
- ç±»å‹åŒ…å«ï¼šå¤§çº²å¯¹åº” / æ¡ˆä¾‹è¡¥å…… / æ•°æ®çº¿ç´¢
- è¦†ç›–æƒ…å†µè¯·å¡«å†™â€œæ˜¯/å¦/éƒ¨åˆ†è¦†ç›–â€
- å†…å®¹æ‘˜è¦ä¸å°‘äº50å­—ï¼Œé¿å…å‹ç¼©è¿‡åº¦
- åŸå§‹è¯æœ¯è¯·èŠ‚é€‰å—è®¿è€…çš„åŸå¥
- å¦‚æœ‰é—æ¼ï¼Œè¯·å¡«å†™å…·ä½“è¡¥é—®å»ºè®®ï¼Œé—®é¢˜ç²¾å‡†å¯æ“ä½œ

---

ã€è®¿è°ˆç›®æ ‡ã€‘
{target}

ã€è®¿è°ˆå¤§çº²ã€‘
{outline}

ã€è®¿è°ˆåŸæ–‡ã€‘
{transcript}
"""
    return call_deepseek_api(prompt)

def main():
    st.set_page_config(page_title="è®¿è°ˆç»“æ„æ•´ç†å·¥å…·", layout="wide")
    st.title("ğŸ“‹ è®¿è°ˆç»“æ„æ•´ç† MVP å·¥å…·")

    # æ–°å¢è®¿è°ˆç›®æ ‡è¾“å…¥æ¡†
    target = st.text_area("è¯·è¾“å…¥è®¿è°ˆç›®æ ‡ï¼ˆä¾‹å¦‚ï¼šæœ¬æ¬¡è®¿è°ˆä¸»è¦ç›®æ ‡æ˜¯ä»€ä¹ˆï¼‰")

    st.markdown("### ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ è®¿è°ˆæ–‡ä»¶ï¼ˆpdfã€docxã€txtï¼‰")
    interview_file = st.file_uploader("ä¸Šä¼ è®¿è°ˆè®°å½•æ–‡ä»¶ï¼š", type=["pdf", "docx", "txt"])

    st.markdown("### ç¬¬äºŒæ­¥ï¼šä¸Šä¼ è®¿è°ˆå¤§çº²ï¼ˆdocxã€txtï¼‰")
    outline_file = st.file_uploader("ä¸Šä¼ è®¿è°ˆå¤§çº²æ–‡ä»¶ï¼š", type=["docx", "txt"])

    if st.button("ğŸš€ å¼€å§‹åˆ†æ") and interview_file and outline_file and target.strip() != "":
        with st.spinner("â³ æ­£åœ¨æå–ä¸åˆ†æå†…å®¹ï¼Œè¯·ç¨å€™..."):
            transcript = extract_text(interview_file)
            outline = extract_text(outline_file)
            result_markdown = analyze_interview(transcript, outline, target)

        st.markdown("### âœ… åˆ†æç»“æœ")
        st.markdown(result_markdown)

        # è¡¨æ ¼è§£æå’ŒExcelå¯¼å‡ºåŠŸèƒ½ï¼ˆæœ€ç»ˆä¿®å¤ç‰ˆï¼‰
        try:
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„markdownè¡¨æ ¼
            table_lines = [line for line in result_markdown.split('\n') 
                         if line.strip().startswith('|') and '---' not in line]
            
            if len(table_lines) >= 2:  # è‡³å°‘åŒ…å«è¡¨å¤´å’Œæ•°æ®è¡Œ
                # ä½¿ç”¨æ›´å¥å£®çš„è¡¨æ ¼è§£ææ–¹å¼
                df = pd.read_csv(io.StringIO('\n'.join(table_lines)), 
                                sep='|', 
                                skipinitialspace=True,
                                header=0)
                df = df.iloc[:, 1:-1]  # ç§»é™¤markdownè¡¨æ ¼é¦–å°¾çš„ç©ºç™½åˆ—
                
                # ç”ŸæˆExcelæ–‡ä»¶ï¼ˆ100%å¯é å†™æ³•ï¼‰
                excel_buffer = io.BytesIO()
                with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                    df.to_excel(writer, index=False, sheet_name='åˆ†æç»“æœ')
                excel_buffer.seek(0)
                
                # æ·»åŠ ä¸‹è½½æŒ‰é’®
                st.download_button(
                    label="ğŸ’¾ ä¸‹è½½Excelè¡¨æ ¼",
                    data=excel_buffer,
                    file_name="åˆ†æç»“æœ.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
            else:
                st.info("â„¹ï¸ åˆ†æç»“æœä¸­æœªåŒ…å«è¡¨æ ¼æ•°æ®")
                
        except pd.errors.EmptyDataError:
            st.info("â„¹ï¸ æœªæ£€æµ‹åˆ°å¯è½¬æ¢çš„è¡¨æ ¼æ•°æ®")
        except Exception as e:
            st.error(f"è¡¨æ ¼è½¬æ¢å¤±è´¥ï¼š{str(e)}")
